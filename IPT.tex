\documentclass[a4paper, 12pt]{article}
\usepackage{preamble}

\title{\textbf{Введение в теорию вероятностей}}
\author{Лектор: проф. Булинский Александр Вадимович}

\begin{document}
    
\fontsize{14pt}{20pt}\selectfont
\maketitle
\vspace{0.3cm}
%\begin{center}
%    \includegraphics[width=0.75\linewidth]{Images/mehmat.png}
%\end{center}
\vspace{1.5cm}
%\begin{center}
    %Конспект: Кирилл Яковлев, 208 группа\\
    % Контакты: \href{https://t.me/fourkenz}{Telegram}, \href{https://github.com/yakovlevki}{GitHub}\\
%\end{center}
    
\newpage
\tableofcontents
\newpage

\section{Лекция 1}
\subsection{Алгебра и сигма-алгебра}
\begin{definition}
    Множество $\Omega$ называется множеством элементарных исходов. Множество $A\in 2^{\Omega}$ назывется событием.
\end{definition}
\begin{definition}
    Множество $\mathcal{A}\in 2^{\Omega}$ такое, что $\mathcal{A}\ne \emptyset$ называется алгеброй, если
    \begin{enumerate}
        \item $\Omega \in \mathcal{A}$
        \item $A\in \mathcal{A} \Rightarrow \bar{A}=\Omega\setminus A\in \mathcal{A}$
        \item $A,B\in \mathcal{A} \Rightarrow A\cup B\in \mathcal{A}$
    \end{enumerate}
\end{definition}
\begin{statement} (Следствия из определения алгебры)
    \begin{enumerate}
        \item $\emptyset\in \mathcal{A}$, так как $\Omega\in \mathcal{A} \Rightarrow \bar{\Omega}=\emptyset\in \mathcal{A}$
        \item $A_1,\dots,A_n \in \mathcal{A} \Rightarrow \bigcup\limits_{i=1}^n A_i\in \mathcal{A}$
        \item $A\cap B\in \mathcal{A}$, если $A,B\in \mathcal{A}$, так как $A\cap B=\overline{\overline{A}\cup\overline{B}}$
        \item $A_1,\dots,A_n \in \mathcal{A} \Rightarrow \bigcap\limits_{i=1}^n A_i\in \mathcal{A}$
        \item $A\setminus B\in \mathcal{A}$, так как $A\setminus B=A\cap \bar{B}$
    \end{enumerate}
\end{statement}
\begin{definition}
    Множество $\mathcal{F}\in 2^{\Omega}$ такое, что $\mathcal{F}\ne \emptyset$ называется $\sigma$-алгеброй, если
    \begin{enumerate}
        \item $\Omega \in \mathcal{F}$
        \item $A\in \mathcal{F} \Rightarrow \bar{A}\in \mathcal{F}$
        \item $\forall i\in \N: A_i\in \mathcal{F} \Rightarrow \bigcup\limits_{n=1}^{\infty}A_i\in \mathcal{F}$
    \end{enumerate} 
\end{definition}
\begin{comm}
    $\mathcal{F}$ - $\sigma$-алгебра $\Rightarrow \mathcal{F}$ - алгебра.
\end{comm}
\begin{example} (Алгебры не являющейся $\sigma$-алгеброй)\\
    Возьмем $\Omega = \R$. Скажем, что множество $A\in \mathcal{A}$, если для некоторого $n$ оно является конечным объединеним полуинтрвалов $(a_i, b_i]$
    \[A=\bigcup\limits_{i=1}^{n}(a_i,b_i]\]
    где $-\infty \leq a_1\leq b_1\leq a_2\leq b_2 \leq ... \leq a_n\leq b_n \leq +\infty$.\\
    \newpage
    Покажем, что $\mathcal{A}$ является алгеброй:
    \begin{enumerate}
        \item $(-\infty, +\infty]=\R\in \mathcal{A}$
        \item Дополнение к полуинтервалу --- объединение двух полуинтервалов.
        \item По определению
    \end{enumerate} 
    Покажем, что $\mathcal{A}$ не является $\sigma$-алгеброй.
    Рассмотрим последовательность множеств из $\mathcal{A}$:
    $A_1=(0,\frac{1}{2}],\ A_2=(\frac{1}{2}, \frac{3}{4}],\ A_3=(\frac{3}{4},\frac{7}{8}],\dots, A_n=(1-\frac{1}{2^{n-1}}, 1-\frac{1}{2^n}],\dots$
    \[\bigcup\limits_{i=1}^{\infty}A_i=(0,1)\not\in \mathcal{A}\]
\end{example}
\begin{comm}
    Наименьшая по включению $\sigma$-алгебра, содержащая $M$, обозначается $\sigma\{M\}=\bigcap\limits_{\alpha}g_{\alpha}$, где $g_{\alpha}$ - $\sigma$-алгебра, содержащая все элементы $M$.
\end{comm}
\subsection{Вероятностная мера}
\begin{definition}
    Мерой на системе множеств $U$ называется функция\\ 
    $\mu: U\to [0,+\infty]$ такая, что
        $\forall i\ne j: A_i\cap A_j=\emptyset$:
        \[\bigcup\limits_{n=1}^{\infty}A_n\in U\]
        выполнено свойство счетной аддитивности:
        \[\mu\left(\ \bigcup\limits_{n=1}^{\infty}A_n\ \right)=\sum_{n=1}^{\infty}\mu(A_n)\]
\end{definition}
\begin{comm}
    Если $U$ --- $\sigma$-алгебра, то условие
    \[\bigcup\limits_{n=1}^{\infty}A_n\in U\]
    можно упустить.
\end{comm}
\begin{example} (Мера Дирака)\\
    Пусть $B\subset S$
    \[\delta_x(B)=\begin{cases}
        1,\ x\in B,\\
        0,\ x\not\in B
    \end{cases}\]
    Упражнение: доказать, что $\delta_x(.)$ является мерой на $2^S$
\end{example}
\begin{definition}
    Мера $P$ на пространстве $(\Omega, \mathcal{F})$ такая, что $P(\Omega)=1$ называется вероятностью.
\end{definition}
\subsection{Дискретные вероятностные пространства}
\begin{definition}
    Пусть $\Omega=\{\omega_n\}_{n\in J}$ не более чем счетно, $\mathcal{F}=2^{\Omega}$, причем
    \[p_n=P(\{\omega_n\})\geq 0,\ \sum_{n\in J} p_n =1\]
    Пусть $A\subset \Omega$, определим вероятность так:
    \[P(A)=\sum\limits_{k: \omega_k\in A}^{n}p_k\]
    такое вероятностное пространство называется дискретным.
\end{definition}
\begin{exercise}
    Доказать, что определенное выше $P$ является вероятностью.
\end{exercise}
%ТУТ ВСТАВКА КАКАЯ-ТО
\begin{definition} (Классическое определение вероятности)\\
    Пусть $|\Omega|=N<\infty$ и положим $p_k=P(\{\omega_k\})=\frac{1}{N}$. Тогда
    \[P(A)=\sum\limits_{k: \omega_k\in A}^{n}p_k=\frac{|A|}{N}=\frac{|A|}{|\Omega|}\]
\end{definition}
%Тут были примеры
\subsection{Пи-системы и лямбда-системы}
\begin{definition}
    Система $M$ подмножеств множества $S$ называется $\pi$-системой, если $A,B\in M \Rightarrow A\cap B\in M$
\end{definition}
\begin{definition}
    Сисмтема $M$ подмножеств множества $S$ называется $\lambda$-системой, если
    \begin{enumerate}
        \item $S\in M$
        \item $A,B\in M$ и $A\subset B \Rightarrow B\setminus A\in M$
        \item $A_1, A_2, \dots \in M$ и $A_n \nearrow A$, то $A\in M$.\\
        ($A_n \nearrow A \Leftrightarrow A_n\subset A_{n+1},\ \forall n\in \N$ и $A=\bigcup\limits_{n=1}^{\infty}A_n$)
    \end{enumerate}
\end{definition}
\begin{theorem}
    Система $\mathcal{F}$ подмножеств $S$ является $\sigma$-алгеброй $\Leftrightarrow \mathcal{F}$ одновременно $\pi$-система и $\lambda$-система.
\end{theorem}
\begin{proof}\tab
    \begin{itemize}
        \item[($\Rightarrow$):] По следствию из определения алгебры: $A,B\in \mathcal{F} \Rightarrow A\cap B\in \mathcal{F}$, значит, $\mathcal{F}$ является $\pi$-системой. Теперь проверим условия $\lambda$-системы:
        \begin{enumerate}
            \item $S\in \mathcal{F}$ выполнено по проеделению алгебры.
            \item $A,B\in \mathcal{F},\ A\subset B$, причем $B\setminus A=B\cap \bar{A} \Rightarrow B\setminus A\in \mathcal{F}$.
            \item $A_1, A_2, \dots\in \mathcal{F},\ A=\bigcup\limits_{n=1}^{\infty}A_n \Rightarrow$ по свойству $\sigma$-алгебры $A\in \mathcal{F}$.
        \end{enumerate}
        \item[($\Leftarrow$):] Проверим определению $\sigma$-алгебры:
        \begin{enumerate}
            \item $S\in \mathcal{F}$ выполнено по первому свойству $\lambda$-системы.
            \item $S\in \mathcal{F},\ A\subset S \Rightarrow S\setminus A\in \mathcal{F}$ выполнено по второму свойству $\lambda$-системы.
            \item Пусть $B_1, B_2,\dots \in \mathcal{F},\ A_m:=\bigcup\limits_{n=1}^m B_n$ при этом
            \[A_m=\bigcup\limits_{n=1}^m B_n=\overline{\left(\bigcap\limits_{n=1}^m \overline{B}_n\right)}\in \mathcal{F} \Rightarrow A_m\nearrow \bigcup\limits_{n=1}^{\infty} B_n \Rightarrow \bigcup\limits_{n=1}^{\infty} B_n\in \mathcal{F}\]
        \end{enumerate}
    \end{itemize}
\end{proof}
\begin{theorem}\label{th1}
    Пусть M --- $\pi$-система, $D$ --- $\lambda$-система и $M\subset D$. Тогда
    \[\sigma\{M\}=\lambda\{M\}\subset D\]
    где $\lambda\{M\}$ --- наименьшая $\lambda$-система, содержащая $M$.
\end{theorem}
\section{Лекция 2}
\subsection{Простейшие свойства конечно-аддитивной вероятностной меры на алгебре}
\begin{theorem}
    Пусть $P$ - конечно-аддитивная вероятностная мера на алгебре $\mathcal{A},\\ P(\Omega)=1,\ P(A\cup B)=P(A)+P(B),\ A\cap B=\emptyset$. Пусть $A,B\in \mathcal{A}$, тогда
    \begin{enumerate}
        \item $A\subset B \Rightarrow P(B\setminus A)=P(B)-P(A)$
        \item $P(A\cup B)=P(A)+P(B)-P(A\cap B)$
        \item Субаддитивность:
        \[P\left(\bigcup\limits_{k=1}^n A_k\right) \leq \sum\limits_{k=1}^{n}P(A_k)\]
        \item Если $P$ - вероятностная мера на $\sigma$-алгебре $\mathcal{F}$, то 
        \[P\left(\bigcup\limits_{k=1}^{\infty}A_k\right)\leq \sum\limits_{k=1}^{\infty}P(A_k)\]
    \end{enumerate}
\end{theorem}
\begin{proof}\tab
    \begin{enumerate}
        \item $B=A\cup(B\setminus A)$ и $A\cap (B\setminus A)=\emptyset \Rightarrow P(B)=P(A)+P(B\setminus A)$
        \item $A\cup B=A\cup (B\setminus A)$ и $A\cap (B\setminus A)=\emptyset \Rightarrow P(A\cup B)=P(A)+P(B\setminus A)$,\\
        $P(B\setminus A)=P(B)-P(A\cap B) \Rightarrow P(A\cup B)=P(A)+P(B)-P(A\cap B)$
        \item По индукции. База $n=2$:\\
        $P(A\cup B)=P(A)+P(B)-P(A\cup B) \leq P(A)+P(B)$, так как $P(A\cup B)\geq 0$
        Пусть верно для $n-1$, тогда\\
        \[P\left(\bigcup\limits_{k=1}^n A_k\right)=P\left(\bigcup\limits_{k=1}^{n-1} A_k \cup A_n\right) \leq \sum\limits_{k=1}^{n-1}P(A_k)+P(A_n)=\sum\limits_{k=1}^{n}P(A_k)\]
        \item \textit{будет позже}
    \end{enumerate}
\end{proof}
\subsection{Непрерывность вероятностной меры}
\begin{definition}
    Конечная неотрицательная функция $\mu$, заданная на алгебре $\mathcal{A}$, называется непрерывной в $\emptyset$, если $\forall A_n$:
    \[A_n \downarrow \emptyset\ (A_{n+1}\subset A_n,\ \forall n\in \N: \bigcap\limits_{n=1}^{\infty}A_n=\emptyset) \Rightarrow \mu(A_n)\to 0\]
\end{definition}
\begin{definition}
    Конечная неотрицательная функция $\mu$ на алгебре $\mathcal{A}$ называется 
    \begin{enumerate}
        \item непрерывной сверху на $A \in \mathcal{A}$, если $\forall A_n : A_n\downarrow A \Rightarrow \mu(A_n)\to \mu(A)$.\\
        \[A_n \downarrow A \Leftrightarrow A_{n+1}\subset A_n,\ \forall n\in \N: \bigcap\limits_{n=1}^{\infty}A_n=A\]
        \item непрерывной снизу на $A\in \mathcal{A}$, если $\forall A_n: A_n\uparrow A \Rightarrow \mu(A_n)\to \mu(A)$.
        \[A_n \uparrow A \Leftrightarrow A_{n}\subset A_{n+1},\ \forall n\in \N: \bigcup\limits_{n=1}^{\infty}A_n=A\]
    \end{enumerate}
\end{definition}
\begin{lemma}
    Пусть $\mu$ - конечная неотрицательная конечно-аддитивная функция на алгебре $\mathcal{A}$, причем $\mu$ непрерывна в $\emptyset$. Тогда $\mu$ непрерывно сверху и снизу на любом $A\in \mathcal{A}$.
\end{lemma}
\begin{proof}
    Докажем непрерывность сверху. Рассмотрим последовательность $A_n \downarrow A \Rightarrow A_n\setminus A \downarrow \emptyset \Rightarrow \mu(A_n\setminus A)=\mu(A_n)-\mu(A)\to 0$. Аналогично, рассмотрим $A_n\uparrow A \Rightarrow A\setminus A_n \downarrow \emptyset \Rightarrow \mu(A\setminus A_n)=\mu(A)-\mu(A_n)\to 0$.
\end{proof}
\begin{theorem} (Критерий счетной-аддитивности)\\
    Пусть $\mu$ - конечная неотрицательная функция на алгебре $\mathcal{A}$. Тогда $\mu$ является счетно-аддитивной на $\mathcal{A}$ тогда и только тогда, когда
    \begin{enumerate}
        \item $\mu$ является конечно-аддитивной.
        \item $\mu$ непрерывна в $\emptyset$.
    \end{enumerate}
\end{theorem}
\begin{proof}\tab
    \begin{itemize}
        \item[$(\Rightarrow)$:]
        Пусть $\mu$ - счетно-аддитивная на $\mathcal{A}$. Рассмотрим $A_n \downarrow \emptyset,\ n\to \infty$ и введем $B_n=A_n\setminus A_{n+1},\ n\in \N$. Эти слои не пересекаются и $\bigcup\limits_{n=N}^{\infty}B_n=A_N$. Применим счетную аддитивность: 
        \[\mu(A_N)=\sum\limits_{n=N}^{\infty}\mu(B_n)<\infty\]
        Этот ряд сходится, значит последовательность (остаточных рядов)
        \[S_N=\sum\limits_{n=N}^{\infty}\mu(B_n)\to 0,\ N\to \infty\]
        \item[$(\Leftarrow)$:] 
        Рассмотрим $A\in \mathcal{A}$, причем
        \[A=\bigcup\limits_{k=1}^{\infty}A_k\]
        где $A_k\in \mathcal{A}$ и $A_i\neq A_j$ при $i\neq j$. Введем $C_n$:
        \[C_n=\bigcup\limits_{k=n}^{\infty}A_n,\ \ C_n\downarrow \emptyset\]
        Заметим, что
        \[A=\bigcup\limits_{k=1}^{\infty}A_k=A_1\cup \dots\cup A_{n-1}\cup C_n\]
        причем $A_1\cup \dots\cup A_{n-1}\in \mathcal{A}$, поскольку $\mathcal{A}$ --- алгебра и $A\in \mathcal{A}$ по условию. Тогда $C_n\in \mathcal{A}$.
        \[\mu(A)=\mu\left(\ \bigcup\limits_{k=1}^{\infty}A_k\right)=\mu(A_1)+ \dots +\mu(A_{n-1})+\mu(C_n)=\sum\limits_{k=1}^{n-1}A_k+\mu(C_n)\]
        Поскольку $C_n\downarrow \emptyset$, то $\mu(C_n)\to 0$ при $n\to \infty$. Тогда, после предельного перехода, получим
        \[\mu\left(\ \bigcup\limits_{k=1}^{\infty}A_k\right)=\sum\limits_{k=1}^{\infty}A_k\]
    \end{itemize}
\end{proof}
\begin{theorem}
    Пусть $P, Q$ - меры на $(\Omega, \mathcal{F})$ и $P=Q$ на алгебре $\mathcal{A}$. Тогда $P=Q$ на алгебре $\sigma\{\mathcal{A}\}$.
\end{theorem}
\begin{proof}
    Сведем к \hyperref[th1]{теореме из прошлой лекции}. Алгебра $\mathcal{A}$\  в частности является $\pi$-системой, рассмотрим 
    \[D=\{B\in \mathcal{F}: P(B)=Q(B)\}\] 
    $\mathcal{A}\subset D$. Проверим, что $D$ является $\lambda$-системой:
    \begin{enumerate}
        \item $P(\Omega)=Q(\Omega)=1 \Rightarrow \Omega\in D$
        \item $P(B\setminus A)=P(B)-P(A),\ Q(B\setminus A)=Q(B)-Q(A)$, причем\\
        $P(A)=Q(A),\ P(B)=Q(B) \Rightarrow P(B\setminus A)=Q(B\setminus A) \Rightarrow B\setminus A\in D$.
        \item
        $A_n\in D,\ A_n \uparrow A=\bigcup\limits_{n=1}^{\infty}A_n$. По свойству непрерывности $P(A_n)\to P(A),\\
        Q(A_n)\to Q(A) \Rightarrow A\in D$.
    \end{enumerate}
    Значит $\sigma\{\mathcal{A}\}\subset D$, что и является утверждением теоремы.
\end{proof}
\subsection{Условные вероятности}
\begin{definition}
    Пусть $(\Omega, \mathcal{F}, P)$ - вероятностное пространство и $A,B\in \mathcal{F},\\
    P(B)\ne 0$. Тогда вероятностью события $A$ при условии $B$ называется
    \[P(A|B)=\frac{P(A\cap B)}{P(B)}\]
\end{definition}
\begin{definition} (Условная вероятность в классическом определении)\\
    Пусть $(\Omega, \mathcal{F}, P)$ вероятностное пространство, $|\Omega|=N<\infty,\ P(\{\omega_k\})=\frac{1}{N}$ и $P(B)=\frac{|B|}{N}$. Тогда
    \[P(A|B)=\frac{|A\cap B|}{|B|}=\frac{\frac{1}{N}\cdot |A\cap B|}{\frac{1}{N}\cdot |B|}=\frac{P(A\cap B)}{P(B)}\]
\end{definition}
\begin{example}
    Три раза бросается правильная монетка. Рассмотрим события:\\
    $A$ - при первом броске выпал герб, $B$ - при трех бросаниях выпало два герба.
    \[\Omega=\{(0,0,0),\ (1,0,0),\ (0,1,0),\ (0,0,1),\ (0,1,1),\ (1,0,1),\ (1,1,0),\ (1,1,1)\}\]
    \[A=\{(1,0,0),\ (1,1,0),\ (1,0,1),\ (1,1,1)\}\] 
    \[B=\{(1,1,0),\ (1,0,1),\ (0,1,1)\}\]
    \[A\cap B=\{(1,1,0),\ (1,0,1)\}\]
    \[P(A|B)=\frac{P(A\cap B)}{P(B)}=\frac{\frac{2}{8}}{\frac{3}{8}}=\frac{2}{3}\]
\end{example}
\begin{theorem} (Формула полной вероятности)\\
    Пусть для всех $k: B_k\in \mathcal{F},\ P(B_k)>0$ и пространство разбивается в их объединение: 
    \[\Omega=B_1\sqcup B_2\sqcup B_3 \sqcup \dots\]
    Тогда определены $P(A|B_k)$, причем для $A\in \mathcal{F}$ верна формула
    \[P(A)=\sum\limits_{k}P(A|B_k)P(B_k)\]
\end{theorem}
\begin{proof}
    \[P(A)=P\left(\bigcup\limits_k (A\cap B_k)\right)=\sum\limits_{k}P(A\cap B_k),\ (A\cap B_k)\cap (A\cap B_m) = \emptyset,\ k\ne m\]
    \[P(A|B_k)=\frac{P(A\cap B_k)}{P(B_k)} \Rightarrow P(A\cap B_k)=P(A|B_k)P(B_k)\]
    отсюда
    \[P(A)=\sum\limits_{k}P(A|B_k)P(B_k)\]
\end{proof}
\begin{consequense} (Формула Байеса)\\
    Пусть $P(A)\ne 0$, тогда верна формула
    \[P(B_n|A)=\frac{P(A|B_n)P(B_n)}{\sum\limits_{k}P(A|B_k)P(B_k)}\]
\end{consequense}
\begin{proof}
    По определению условной вероятности и формуле полной вероятности, получим
    \[P(B_n|A)=\frac{P(B_n\cap A)}{P(A)}=\frac{P(A|B_n)P(B_n)}{\sum\limits_{k}P(A|B_k)P(B_k)}\]
\end{proof}
\section{Лекция 3}
\subsection{Независимые события}
\begin{definition}
    Если $P(A|B)=P(A)$, то при $P(B)\ne 0$ выполнено
    \[P(A\cap B)=P(A)P(B)\]
    В этом случае события $A$ и $B$ называются независимыми.
\end{definition}
\begin{example}
    В колоде 36 карт. Выбираем одну карту из колоды. Рассмотрим события: $A$ - вытянули карту масти треф, $B$ - вытянули туз.
    \[P(A)=\frac{1}{4},\ P(B)=\frac{4}{36}=\frac{1}{9},\ P(A\cap B)=\frac{1}{36}\]
    \[P(A)P(B)=\frac{1}{4}\cdot\frac{1}{9}=\frac{1}{36}=P(A\cap B)\]
    значит события независимы.
\end{example}
\begin{definition}
    Пусть $A_1,\dots,A_n$ - события. Они называются независимыми в совокупности, если $\forall i_1<i_2<\dots<i_n\leq n$:
    \[P(A_{i_1}\cap A_{i_2}\cap \dots \cap A_{i_k})=P(A_{i_1}) P(A_{i_2}) \dots P(A_{i_k})\]
\end{definition}
\begin{definition}
    Пусть $A_1,\dots,A_n$ - события. Они называются попарно независимыми, если $\forall i,j\in \{1,\dots,n\},\ i\ne j:$
    \[P(A_i\cap A_j)=P(A_i)P(A_j)\]
\end{definition}
\begin{example} (Попарной независимости событий недостаточно для их независимости в совокупности)\\
    Рассмотрим $(\Omega, \mathcal{F}, P)$ в рамках классического определения: 
    \[\Omega=\{\omega_1,\omega_2,\omega_3,\omega_4\},\ A_1=\{\omega_1, \omega_2\},\ A_2=\{\omega_1,\omega_3\},\ A_3=\{\omega_1,\omega_4\},\ A_i\cap A_j=\{\omega_1\}\] 
    Тогда 
    \[P(A_i\cap A_j)=P(\{\omega_1\})=\frac{1}{4}\] 
    но с другой стороны 
    \[P(A_1\cap A_2\cap A_3)=\frac{1}{4} \ne \frac{1}{2}\cdot\frac{1}{2}\cdot\frac{1}{2}\]
\end{example}
\begin{definition}
    Система $\{A_t,\ t\in T\}$ состоит из независимых событий, если для любого конечного $F\subset T,\ F=\{t_1,\dots,t_n\}$, события $A_{t_1},\dots, A_{t_n}$ независимы в совокупности.
\end{definition}
\begin{lemma}\label{lm1}
    Пусть $A_1,\dots,A_n$ - независимые события. Рассмотрим $B_1,\dots,B_n$ такие, что $B_i=A_i$ или $B_i=\overline{A_i}$. Тогда $B_1,\dots,B_n$ - независимые события. 
\end{lemma}
\begin{proof}
    Достаточно рассмотреть случай $B_j=\overline{B_j},\ B_i=A_i,\\ \forall i\ne j$. Возьмем $I=\{i_1,\dots,i_k\},\ 1\leq i_1<\dots<i_k\leq n$ и проверим, что
    \[P(B_{i_1}\cap \dots \cap B_{i_k})=P(B_{i_1})\dots P(B_{i_k}) \eqno{(*)}\]
    Рассмотрим случаи:
    \begin{enumerate}
        \item $j\not\in I$. Тогда $B_i=A_i$ и ($*$) выполнено.
        \item $j\in I \Rightarrow \exists\ m: j=i_m$. Тогда 
        \begin{multline*}
            P(B_{i_1}\cap \dots \cap B_{i_k})=P(A_{i_1}\cap \dots\cap \overline{A_{i_m}}\cap \dots \cap A_{i_k}) \overset{(1)}{=}\\
            \overset{(1)}{=} P((A_{i_1}\cap \dots \cap A_{i_{m-1}}\cap A_{i_{m+i}}\cap A_{i_k})\setminus(A_{i_1}\cap \dots \cap A_{i_{m-1}}\cap A_{i_m}\cap A_{i_{m+1}}\cap \dots\cap A_{i_k}))\overset{(2)}{=}\\
            \overset{(2)}{=} P(A_{i_1}\cap \dots \cap A_{i_{m-1}}\cap A_{i_{m+i}}\cap A_{i_k})-P(A_{i_1}\cap \dots \cap A_{i_k})=\\\
            =P(A_{i_1})\dots P(A_{i_{m-1}})P(A_{i_{m+1}})\dots P(A_{i_k})-P(A_{i_1})\dots P(A_{i_k})\overset{(3)}{=}\\
            \overset{(3)}{=} P(A_{i_1})\dots P(A_{i_{m-1}})P(A_{i_{m+1}})\dots P(A_{i_k})(1-P(A_{i_m}))=\\=P(B_{i_1})\dots P(B_{i_m})\dots P(B_{i_k})
        \end{multline*}
        (1): $A\cap \overline{C}=A\setminus (A\cap C)$\\
        (2): $A\subset B \Rightarrow P(B\setminus A)=P(B)-P(A)$\\
        (3): Выносим общий множитель за скобку. 
    \end{enumerate}
\end{proof}
\begin{theorem}
    Пусть $\phi(n)$ - функция Эйлера, $p_i$ - $i$-е простое число. Тогда
    \[\phi(n)=n\cdot\prod\limits_{i=1}^{m}\left(1-\frac{1}{p_i}\right)\]
\end{theorem}
\begin{proof}
    Введем $\Omega=\{1,\dots n\},\ \mathcal{F}=2^{\Omega},\ P(\{i\})=\frac{1}{n},\ i=1,\dots,n$. Проведем следующий эксперимент: из чисел $1,\dots,n$ наугад выбирается число. Рассмотрим событие $A$ - выбрано число, взаимно простое с $n$. Тогда
    \[P(A)=\frac{\phi(n)}{n}\]
    Рассмотрим события $A_i$ - выбраное число делится на $p_i$. Отсюда
    \[A_i=\{p_i,\ 2p_i,\ \dots,\ \frac{n}{p_i}\cdot p_i\} \Rightarrow P(A_i)=\frac{\frac{n}{p_i}}{n}=\frac{1}{p_i}\]
    Для любых $1\leq i_1<\dots<i_k\leq n$:
    \[A_{i_1}\cap \dots\cap A_{i_k}=\{p_{i_1}\dots p_{i_k},\ 2p_{i_1}\dots p_{i_k},\ \dots,\ \frac{n}{p_{i_1}\dots p_{i_k}}\cdot p_{i_1}\dots p_{i_k}\}\]
    \[P(A_{i_1}\cap \dots\cap A_{i_k})=\frac{\frac{n}{p_{i_1}\dots p_{i_k}}}{n}=\frac{1}{p_{i_1}\dots p_{i_k}}=P(A_{i_1})\dots P(A_{i_k})\]
    Значит $A_{i_1},\dots, A_{i_k}$ независимы $\Rightarrow$ по \hyperref[lm1]{лемме} $\overline{A_{i_1}},\dots, \overline{A_{i_k}}$ независимы. Тогда
    \begin{multline*}
        P(A)=P(\overline{A_{P_1}}\cap \overline{A_{p_2}}\cap \dots \cap \overline{A_{p_m}})=P(\overline{A_{p_1}})P(\overline{A_{p_2}})\dots P(\overline{A_{p_n}})=\\
        =(1-P(A_{p_1}))(1-P(A_{p_2}))\dots (1-P(A_{p_m}))=\prod\limits_{i=1}^{m}\left(1-\frac{1}{p_i}\right)
    \end{multline*}
    значит
    \[\prod\limits_{i=1}^{m}\left(1-\frac{1}{p_i}\right)=\frac{\phi(n)}{n}\ \Rightarrow\ \phi(n)=n\cdot \prod\limits_{i=1}^{m}\left(1-\frac{1}{p_i}\right)\]
\end{proof}
\subsection{Независимые системы событий}
\begin{definition} %дописать эквивалентность
    Системы событий $\mathcal{G}_1,\dots,\mathcal{G}_n$ называются независимыми, если $\forall 1\leq i_1 < \dots <i_k\leq n$ и $\forall A_i\in \mathcal{G}_i: A_{i_1},\dots,A_{i_k}$ независимы.
\end{definition}
\begin{definition}
    Пусть все $\mathcal{G}_k$ содержат $\Omega$ (например $\mathcal{G}_k$ - алгебры), то они независимы, если $\forall A_i\in \mathcal{G}_i$:
    \[P(A_1\cap \dots\cap A_n)=P(A_1)\dots P(A_n)\]
\end{definition}
\begin{statement}
    Если все $\mathcal{G}_k$ содержат $\Omega$, то эти определения эквивалентны.
\end{statement}
\begin{proof}\tab
    \begin{enumerate}
        \item Первое определение влечет второе, поскольку в качестве $i_1,\dots,i_k$ можно взять $1,\dots,n$.
        \item Докажем, что второе определение влечет первое:
        Рассмотрим произвольный набор событий $A_{i_1}, \dots, A_{i_k}$ и определим события $B_1,\dots,B_n$:
        \[B_m=\begin{cases}
            A_m,\ m\in \{i_1,\dots,i_k\},\\
            \Omega,\ m\not\in \{i_1,\dots,i_k\}.
        \end{cases}\]
        Тогда
        \[B_1\cap \dots\cap B_n=A_{i_1}\cap \dots\cap A_{i_k}\cap (\Omega \cap \dots \cap \Omega)=A_{i_1}\cap \dots\cap A_{i_k}\]
        значит
        \begin{multline*}
            P(A_{i_1}\cap \dots\cap A_{i_k})=P(B_1\cap \dots\cap B_n)=\\
            =P(A_{i_1})\dots P(A_{i_k})\cdot (1 \dots 1)=P(A_{i_1})\dots P(A_{i_k})
        \end{multline*}
    \end{enumerate}
\end{proof}
\begin{theorem}
    Пусть $\pi$-системы $M_1,\dots,M_n$ (подмножества $\Omega$ из $\mathcal{F}$) независимы. Тогда независимы $\sigma\{M_1\},\dots,\sigma\{M_n\}$.
\end{theorem}
\begin{proof}
    Рассмотрим все события $B_1$ такие, что выполнено:
    \[P(B_1\cap B_2\cap \dots \cap B_n)=P(B_1)P(B_2)\dots P(B_n)\eqno(*)\]
    для проиизвольных $B_2\in M_2,\ \dots,\ B_n\in M_n$. Назовем такие $B_1$ системой $D_1$. Покажем, что $D_1$ является $\lambda$-системой:
    \begin{enumerate}
        \item ($\Omega \in D_1$)
        \begin{multline*}
            P(\Omega\cap B_2\cap \dots\cap B_n)=P(B_2\cap B_n)=\\
            =P(B_2)\dots P(B_n)=P(\Omega)P(B_2)\dots P(B_n)
        \end{multline*}
        Значит $\Omega \in D_1$.
        \item ($A_1,A_2\in D_1,\ A_1\subset A_2 \Rightarrow A_1\setminus A_2\in D_1$)\\
        Пусть $B_i, B_j$ - события, для которых выполнено $(*)$ и $B_j\subset B_i$
        \newline
        \begin{multline*}
            P((B_i\setminus B_j)\cap (B_2\cap \dots\cap B_n))\overset{(1)}{=}\\
            \overset{(1)}{=}P((B_i\cap B_2\cap \dots\cap B_n)\setminus (B_j\cap B_2\cap \dots\cap B_n))=\tab[4cm]\\
            =P(B_i\cap B_2\cap \dots\cap B_n)-P(B_j\cap B_2\cap \dots\cap B_n)=\tab[1cm]\\
            \tab[3cm]=P(B_i)\dots P(B_n)-P(B_j)\dots P(B_n)=\tab[2.5cm]\\
            \tab[3.5cm]=P(B_2)\dots P(B_n)(P(B_i)-P(B_j))=\\
            =P(B_i\setminus B_j)P(B_2)\dots P(B_n)
        \end{multline*}
        (1): $(B\setminus A)\cap C=(B\cap C)\setminus (A\cap C)$
        \item ($A_1,A_2\dots \in D,\ A_i\subset A_{i+1}$ и $A_i\uparrow A \Rightarrow A\in D_1$)\\
        Пусть $B_{i} \uparrow B$. Тогда
        \[(B_{i}\cap B_2\cap \dots\cap B_n) \uparrow (B\cap B_2\cap \dots\cap B_n)\]
        Поскольку вероятностная мера непрерывна, то
        \[P(B_i\cap B_2\cap \dots \cap B_n) \to P(B\cap B_2\cap \dots \cap B_n)\]
        причем 
        \[P(B_i)P(B_2)\dots P(B_n)\to P(B)P(B_2)\dots P(B_n)\]
        значит
        \[P(B\cap B_2\cap \dots \cap B_n)=P(B)P(B_2)\dots P(B_n)\]
        а это означает, что $B\in D_1$.
    \end{enumerate}
    Значит $D_1$ - это $\lambda$-система. Тогда, поскольку $M_1\subset D_1$, то $\sigma\{M_1\}\subset D_1$.\\
    Далее определим $D_2$ --- это будут все события $B_2$ такие, что
    \[P(B_1\cap B_2\cap \dots \cap B_n)=P(B_1)P(B_2)\dots P(B_n)\]
    для произвольных $B_1\in \sigma\{M_1\},\ B_3\in M_3,\ \dots,\ B_n\in M_n$. Аналогично, $D_2$ --- $\lambda$-система, причем $D_2$ независима с $\sigma\{M_1\}$ и $\sigma\{M_2\}\subset D_2$ следовательно $\sigma\{M_1\}$ и $\sigma\{M_2\}$ независимы. Аналогично рассуждаем про $D_3,\dots,D_n$ и получаем, что $\sigma\{M_1\},\dots,\sigma\{M_n\}$ независимы.
\end{proof}
\subsection{Лемма Бореля-Кантелли}
\begin{lemma} (Лемма Бореля-Кантелли)
    \begin{enumerate}
        \item Если события $A_1, A_2, \dots$ таковы, что
        \[\sum\limits_{n=1}^{\infty}P(A_n)<\infty\]
        то вероятность события "произошло бесконенчное число $A_n$"\ равна 0.
        \item Если $A_1, A_2, \dots$ независимые события, такие, что
        \[\sum\limits_{n=1}^{\infty}P(A_n)=\infty\]
        то вероятность события "произошло бесконенчное число $A_n$"\ равна 1.
    \end{enumerate}
\end{lemma}
\begin{proof}
    Заметим, что событие "произошло бесконенчное число $A_n$"\ можно представить в виде
    \[A=\bigcap\limits_{n=1}^{\infty}\left(\ \bigcup\limits_{k=n}^{\infty}A_k\right)\]
    Тогда
    \begin{enumerate}
        \item При $n\to \infty$
        \[P\left(\ \bigcap\limits_{n=1}^{\infty}\left(\ \bigcup\limits_{k=n}^{\infty}A_k\ \right)\right)\leq P\left(\ \bigcup\limits_{k=n}^{\infty}A_k\right)\leq \sum\limits_{k=n}^{\infty}P(A_k)\to 0\]
        \item Это равносильно тому, что
        \[P\left(\ \overline{\bigcap\limits_{n=1}^{\infty}\left(\ \bigcup\limits_{k=n}^{\infty}A_k\right)}\right)=0\]
        \begin{multline*}
            P\left(\ \overline{\bigcap\limits_{n=1}^{\infty}\left(\ \bigcup\limits_{k=n}^{\infty}A_k\right)}\right)=P\left(\ \bigcup\limits_{n=1}^{\infty}\left(\ \overline{\bigcup\limits_{k=n}^{\infty}A_k}\right)\right)=\\
            =P\left(\ \bigcup\limits_{n=1}^{\infty}\left(\ \bigcap\limits_{k=n}^{\infty}\overline{A_k}\right)\right)\leq \sum\limits_{n=1}^{\infty}P\left(\ \bigcap\limits_{k=n}^{\infty}\overline{A_k}\right)
        \end{multline*}
        Покажем, что $\forall n\in \N$:
        \[P\left(\ \bigcap\limits_{k=n}^{\infty}\overline{A_k}\right)=0\]
        Поскольку вероятностная мера непрерывна, то 
        \[P\left(\ \bigcap\limits_{k=n}^{\infty}\overline{A_k}\right)=\lim\limits_{N\to\infty}P\left(\ \bigcap\limits_{k=n}^{N}\overline{A_k}\right)\]
        $A_1,\dots,A_n$ независимы $\Rightarrow \overline{A_1}, \dots, \overline{A_n}$ независимы по лемме. Поэтому
        \begin{multline*}
            P\left(\ \bigcap\limits_{k=n}^{N}\overline{A_k}\right)=\prod\limits_{k=n}^{N}P(\overline{A_k})=\prod\limits_{k=n}^{N}(1-P(A_k))\overset{(1)}{\leq}\\
            \overset{(1)}{\leq} \prod\limits_{k=n}^{N} e^{-P(A_k)}=\text{exp}{\left(-\sum\limits_{k=n}^{N}P(A_k)\right)}
        \end{multline*}
        (1): Используем неравенство: $\forall x\in \R,\ 1-x\leq e^{-x}$ (Можно доказать, разложив экспоненту в степенной ряд).\\
        При $N\to \infty$ получим
        \[P\left(\ \bigcap\limits_{k=n}^{\infty}\overline{A_k}\right)\leq\text{exp}{\left(-\sum\limits_{k=n}^{\infty}P(A_k)\right)}\to 0\]
    \end{enumerate}
\end{proof}
\begin{lemma} (Лемма о групировке)\\
    Пусть имеется семейство $\mathcal{A}_t,\ t\in T$ независимых $\sigma$-алгебр.\\
    Возьмем $I_1,I_2,\dots\subset T: I_k\cap I_m=\emptyset,\ \forall k\ne m$ и для $I\subset T$ введем\\
    $\sigma\{I\}=\sigma\{\mathcal{A}_t,\ t\in I\}$. Тогда $\sigma\{I_1\}, \sigma\{I_2\}, \dots$ - независимые $\sigma$-алгербы.
\end{lemma}
\section{Лекция 4}
\subsection{Функция распределения и плотность}
\begin{definition}
    Пусть $(S, \tau)$ - топологическое пространство. Наименьшая $\sigma$-алгебра, содержащая все открытые множества называется Борелевской $\sigma$-алгебро и обозначается $\mathcal{B}(S)$
\end{definition}
\begin{definition}
    Пусть $P$ - вероятностная мера на $(\R, \mathcal{B}(\R))$. Функция 
    \[F(x)=P((-\infty, x])\]
    называется функцией распределения вероятностной меры.
\end{definition}
\begin{theorem}
    Функция распределения обладает следующими свойствами:
    \begin{enumerate}
        \item $F$ не убывает
        \item $F$ непрерывна справа $\forall x\in \R$
        \item $\lim\limits_{x\to -\infty}F(x)=0$
        \item $\lim\limits_{x\to +\infty}F(x)=1$
    \end{enumerate}
\end{theorem}
\begin{proof}\tab
    \begin{enumerate}
        \item $x\leq y \Rightarrow (-\infty, x] \subset (-\infty, y] \Rightarrow P((-\infty, x])\leq P((-\infty, y]) \Rightarrow F(x)\leq F(y)$
        \item Если $x_n$ монотонно стремится в $x$, то $(-\infty, x_n]\downarrow(-\infty, x]$, значит, по свойству непрерывности вероятностной меры, $P((-\infty, x_n]) \to P((-\infty,x])\\ \Rightarrow F(x_n)\to F(x)$.
        \item и\ \ 4. напрямую следуют из непрерывности вероятностной меры.
    \end{enumerate}
\end{proof}
\begin{theorem}
    Если функция $F$ обладается свойствами $(1)-(4)$, то на $(\R, \mathcal{B}(\R))$ существует единственная вероятностная мера, такая, что $\forall x\in \R:$
    \[F(x)=P((-\infty,x])\]
    Это задает взаимно-однозначное соответствие между вероятностными мерами и функциями распределения.
\end{theorem}
\begin{definition}
    Пусть $p(x)$ вещественная кусочно-непрерывная функция. Если $\forall x\in \R: p(x)\geq 0$ и интеграл Римана
    \[\int\limits_{\R}p(u)\ du=1\]
    то такая $p(x)$ называется плотностью.
\end{definition}
\begin{statement}
    \[F(x)=\int\limits_{-\infty}^{x}p(u)\ du\]
    является функцией распределения.\\
    (для нее выполнены свойства $(1)-(4)$)
\end{statement}
\begin{example}
    Равномерное распределение на $[a,b]\subset \R$
    \[p(x)=\begin{cases}
        \frac{1}{b-a},& x\in [a,b],\\
        0,&x\not\in [a,b].
    \end{cases}\]
    \[
    \begin{tikzpicture}[>=stealth, scale=1.2]
    \def\a{-1.3}
    \def\b{2.2}
    \def\h{1.5}
    \draw[->] (-2.5,0) -- (3,0) node[below] {$x$};
    \draw[->] (0,-0.4) -- (0,2.5) node[left] {$y$};
    \draw (\a,0.1) -- (\a,-0.1) node[below] {$a$};
    \draw (\b,0.1) -- (\b,-0.1) node[below] {$b$};
    \draw (0,\h) -- (0,\h) node[above right] {$\frac{1}{b-a}$};
    \draw[->] (\a-0.15,0) -- (\a,0);
    \draw[dashed] (\a,0) -- (\a,\h);
    \draw[thick] (\a,\h) -- (\b,\h);
    \draw[dashed] (\b,0) -- (\b,\h);
    \draw[->] (\b+0.15,0) -- (\b,0);
    \end{tikzpicture}
    \]
\end{example}
\begin{example}
    Экспоненциальное распределение с параметром $\lambda>0$
    \[p(x)=\begin{cases}
        \lambda e^{-\lambda x},& x\geq 0,\\
        0,& x<0.
    \end{cases}\]
    \[
    \begin{tikzpicture}[>=stealth, scale=1.3]
    \draw[->] (-1,0) -- (4,0) node[below] {$x$};
    \draw[->] (0,-0.4) -- (0,2.5) node[left] {$y$};
    \draw (0,0.1) -- (0,-0.1) node[below left] {$0$};
    \draw (0.1,1.5) -- (-0.1,1.5) node[left] {$\lambda$};
    \draw[thick] (-1,0) -- (0,0);
    \draw[thick,->] (-0.15,0) -- (0,0);
    \draw[thick] (0,1.5) .. controls (0.5,0.9) and (1,0.55) .. (3.8,0.1);
    %\draw[thick, domain=0:3.8, samples=100] plot (\x, {1.5*exp(-1.5*\x)});
    \end{tikzpicture}
    \]
\end{example}
\begin{example}
    Гауссовское (нормальное) распределение
    \[p(x)=\frac{1}{\sigma\sqrt{2\pi}}\cdot e^{-\frac{(x-a)^2}{2\sigma^2}}\]
    \[
    \begin{tikzpicture}[>=stealth, scale=1.3]
    \def\a{1}
    \draw[->] (-1.5,0) -- (3.5,0) node[below] {$x$};
    \draw[->] (0,-0.4) -- (0,2.5) node[left] {$y$};
    \draw (\a,0.1) -- (\a,-0.1) node[below] {$a$};
    \draw[dashed] (\a,0) -- (\a,1.5);
    %\draw (0.1,0.5) -- (-0.1,0.5) node[left] {$\frac{1}{\sigma\sqrt{2\pi}}$};
    \draw[thick, domain=-1.5:3.5, samples=100] plot (\x, {1.5*exp(-(\x-\a)^2/0.5)});
    \end{tikzpicture}
    \]
\end{example}
\begin{exercise}
    Доказать, что в каждом из этих случаев действительно выполнено
    \[\int\limits_{\R} p(x)\ dx =1\]
\end{exercise}
\subsection{Случайные величины}
\begin{definition}
    Рассмотрим вероятностные пространства $(\Omega, \mathcal{F}),\ (S, \mathcal{B})$. Отображение $X: \Omega \to S$ называется $\mathcal{F}|\mathcal{B}$ измеримым (или случайным элементом), если $\forall B\in \mathcal{B}: X^{-1}(B)\in \mathcal{F}$. В этом случае, пишут $X\in \mathcal{F}|\mathcal{B}$.
\end{definition}
\begin{definition}
    Рассмотрим вероятностные пространства $(\Omega, \mathcal{F})$ и $(\R, \mathcal{B}(\R))$. Если $X\in \mathcal{F}|\mathcal{B}(\R)$, то $X$ называется случайной величиной.
\end{definition}
\begin{theorem}
    Рассмотрим $f: V \to S$ и систему $M$ подмножеств $S$. Определим множество $f^{-1}(M)=\{f^{-1}(B):B\in M\}$ и рассмотрим $\sigma\{f^{-1}(M)\}$. Тогда
    \[\sigma\{f^{-1}(M)\}=f^{-1}(\sigma\{M\})\]
\end{theorem}
\begin{proof}
    Упражнение.
\end{proof}
\begin{consequense}
    Пусть $f:V\to S$ и $\mathcal{B}=\sigma\{M\}$. Пусть $f^{-1}(B)\in \mathcal{F}\ (B\in \mathcal{B})$.\\ 
    Тогда $f\in \mathcal{F}|\mathcal{B}$.
\end{consequense}
\begin{consequense}
    Пусть $(V, \tau)$ и $(S, \nu)$ - топологические пространства. Если $f: V\to S$ непрерывна $(f^{-1}(\nu)\subset \tau)$, то $f\in \mathcal{B}(V)|\mathcal{B}(S)$
\end{consequense}
\subsection{Распределение случайного элемента}
\begin{definition}
    Рассмотрим вероятностные пространства $(\Omega, \mathcal{F})$ и $(S, \mathcal{B})$. Пусть $X:\Omega \to S,\ X\in \mathcal{F}|\mathcal{B}$. Распределением случайного элемента $X$ называется вероятностная мера $P_X$ на $(S,\mathcal{B})$ такая, что
    \[P_X(B)=P(X^{-1}(B))\]
    для любого $B\in \mathcal{B}$.
\end{definition}
\begin{exercise}
    Проверить, что $P_X$ является вероятностной мерой.
\end{exercise}
\begin{definition} 
    Если случайный элемент $X$ распределен по распределению $Q$, то пишут $X \sim Q$
\end{definition}
\begin{definition}
    Случайные элементы $X_k:\Omega \to S,\ k=1,\dots,n$ называются независимыми, если независимы $\sigma$-алгебры $\sigma\{X_1\}, \dots, \sigma\{X_n\}$, где\\
    $\sigma\{X_i\}=\{X^{-1}_i(B),\ B\in \mathcal{B}\}$, что означает
    \[P(X_1\in B_1, \dots, X_n\in B_n)=\prod\limits_{k=1}^{n}P(X_k\in B_k)\]
\end{definition}
\begin{definition}
    Случайная величина $X$ называется дискретной, если она принимает не более чем счетное число значений.
\end{definition}
\begin{definition} (Биномиальное распределение)\\
    Дискретная случайная величина $X$ имеет биномиальное распределение:\\
    $X \sim B(n,p)$, где $n\in \N,\ 0<p<1$, если
    \[P(X=k)=C_n^k p^k (1-p)^{n-k},\ k=0,1,\dots,m\]
\end{definition}
\begin{definition} (Распределение Пуассона)\\
    Дискретная случайная величина распределяется по Пуассону:\\
    $X\sim Pois(\lambda)$, если
    \[P(X=k)=\frac{\lambda^k e^{-\lambda}}{k!},\ k\in \Z_+\]
\end{definition}
\begin{theorem} (Классическая теорема Пуассона)\\
    Если $n\cdot p(n)\to \lambda>0,\ n\to \infty$, то
    \[C_n^k p^k(n)(1-p(n))^{n-k}\to \frac{\lambda^k e^{-\lambda}}{k!}\]
\end{theorem}
\begin{proof}
    \[p^k(n) = \frac{(n\cdot p(n))^k}{n^k} \to \frac{\lambda^k}{n^k}\]
    Заметим, что
    \[n\cdot p(n)\to \lambda \Rightarrow p(n)\to 0\]
    Значит
    \[(1-p(n))^{n-k}=\frac{(1-p(n))^n}{(1-p(n))^k}\to (1-p(n))^n\]
    Таким обзаром
    \[\frac{n!}{k!(n-k)!}\cdot p^k(n)(1-p(n))^{n-k}\to \frac{n!}{k!(n-k)!}\cdot \frac{\lambda^k}{n^k}(1-p(n))^n\]
    Нам нужно, чтобы
    \[\frac{n!}{n^k(n-k)!}\cdot (1-p(n))^n\to e^{-\lambda}\]
    \[(1-p(n))^n=(1-p(n))^{\frac{n\cdot p(n)}{p(n)}}=((1-p(n))^{-\frac{1}{p(n)}})^{-n\cdot p(n)}\to e^{-\lambda}\]
    Значит, остается доказать, что
    \[\frac{n!}{n^k(n-k)!}\to 1\]
    Действительно
    \[\frac{n!}{n^k (n-k)!}=\frac{n(n-1)(n-2)\dots(n-k+1)}{n^k}\to 1\]
    Объединив результаты, получим
    \[\frac{n!}{k!(n-k)!}\cdot p^k(n)(1-p(n))^{n-k}\to \frac{\lambda^k e^{-\lambda}}{k!}\]
\end{proof}
\textit{тут пропущена теорема которую я не понял}
\section{Лекция 5}
\subsection{Современная теорема Пуассона}
\begin{theorem}
    Пусть $X_1, \dots, X_n$ - независимые Бернуллиевские случайные элементы,
    $P(X_i=1)=p_i,\ P(X_i=0)=1-p_i,\ S_n=X_1+\dots+X_n,\ Y\sim Pois(\lambda)$, где $\lambda=p_1+\dots+p_n$. Тогда
    \[\sup\limits_{B\in \mathcal{B}(\R)}|P(S_n\in B)-P(Y\in B)|\leq \sum\limits_{k=1}^{n}p_k^2\]
    Для доказательства этой теоремы потребуются две леммы
\end{theorem}
\begin{lemma}
    Если $Y_1, \dots, Y_n$ независимые случайные величины, причем $Y_k \sim Pois(\lambda_k)$. Тогда
    \[\sum\limits_{k=1}^{n}Y_k \sim Pois\left(\sum\limits_{k=1}^{n}\lambda_k\right)\]
\end{lemma}
\begin{proof}
    Сначала докажем, что $Y_1 + Y_2 \sim Pois(\lambda_1+\lambda_2)$ при условии, что $Y_1 \sim Pois(\lambda_1),\ Y_2 \sim Pois(\lambda_2)$.
    \begin{multline*}
        P(Y_1+Y_2=m)\overset{(1)}{=}\sum\limits_{i=0}^{m}P(Y_1+Y_2=m,\ Y_1=i)=\\
        =\sum\limits_{i=0}^{m}P(Y_1=i,\ Y_2=m-i)=\sum\limits_{i=0}^{m}P(Y_1=i)P(Y_2=m-i)\tab[2.5cm]\\
        \tab[1.5cm]=\sum\limits_{i=0}^{m}\left(\frac{\lambda_1^i e^{-\lambda_1}}{i!}\cdot \frac{\lambda_2^{m-i}e^{-\lambda_2}}{(m-i)!}\right)\overset{(2)}{=}\frac{e^{-(\lambda_1+\lambda_2)}}{m!}\cdot \sum\limits_{i=0}^{m} \left(\frac{m!}{i! (m-i)!}\lambda_1^i \lambda_2^{m-i}=\right)=\\
        =\frac{e^{-(\lambda_1+\lambda_2)}}{m!}(\lambda_1+\lambda_2)^m
    \end{multline*}
    (1): По формуле полной вероятности\\
    (2): Домножили и поделили на $m!$\\
    Далее, индукция по $n$: база очевидна, $Y_1+\dots+Y_n=(Y_1+\dots+Y_{n-1})+Y_n$.\\
    По предположению индукции $Y_1+\dots+Y_{n-1}\sim Pois(\lambda_1+\dots+\lambda_{n-1})$
    Поэтому, если $Y_1+\dots+Y_{n-1}$ и $Y_n$ независимы, то
    \[\sum\limits_{k=1}^{n}Y_k \sim Pois\left(\sum\limits_{k=1}^{n}\lambda_k\right)\]
    \textit{Остается показать, что $Y_1+\dots+Y_{n-1}$ и $Y_n$ независимы}
\end{proof}
\begin{lemma}
    Пусть $X, Y$ случайные величины. Тогда $\forall B\in \mathcal{B}(\R)$ выполнено:
    \[|P(X\in B)-P(Y\in B)|\leq P(X\neq Y)\]
\end{lemma}
\begin{proof}
    Рассмотрим разбиение $\Omega$ на четыре части:\\
    $X(\omega)\in B$ и $Y(\omega)\in B$,\ $X(\omega)\in B$ и $Y(\omega)\not\in B$,\ $X(\omega)\not\in B$ и $Y(\omega)\in B$,\ $X(\omega)\not\in B$ и $Y(\omega)\not\in B$. Тогда по формуле полной вероятности:
    \begin{multline*}
        P(X\in B)-P(Y\in B)=P(X\in B,\ Y\in B)+\\
        +P(X\in B,\ Y\not\in B)-P(Y\in B,\ X\in B)-P(Y\in B, X\not\in B)\leq \\
        \leq P(X\in B,\ Y\not\in B)\leq P(X\neq Y)
    \end{multline*}
    Аналогично можно показать, что $P(Y\in B)-P(X\in B)\leq P(X\neq Y)$. Тогда 
    \[|P(X\in B)-P(Y\in B)|\leq P(X\neq Y)\]
\end{proof}
Теперь можно перейти к доказательству теоремы. Напомним ее условие
\begin{theorem}
    Пусть $X_1, \dots, X_n$ - независимые Бернуллиевские случайные элементы,
    $P(X_i=1)=p_i,\ P(X_i=0)=1-p_i,\ S_n=X_1+\dots+X_n,\ Y\sim Pois(\lambda)$, где $\lambda=p_1+\dots+p_n$. Тогда
    \[\sup\limits_{B\in \mathcal{B}(\R)}|P(S_n\in B)-P(Y\in B)|\leq \sum\limits_{k=1}^{n}p_k^2\]
\end{theorem}
\begin{proof}
    \begin{multline*}
        |P(S_n\in B)-P(Y\in B)|=|P(X_1+\dots+X_n \in B)-P(Y\in B)|\overset{(1)}{\leq}\\
        \overset{(1)}{\leq} P(X_1+\dots+X_n\neq Y)\overset{(2)}{=}P(X_1+\dots+X_n\neq Y_1+\dots+Y_n)\overset{(3)}{\leq}\\
        \overset{(3)}{\leq} P\left(\bigcup\limits_{k=1}^{n}\{X_k\neq Y_k\}\right)\overset{(4)}{\leq} \sum\limits_{k=1}^{n}P(X_k\neq Y_k)
    \end{multline*}
    Пояснения:\\
    (1): По лемме 2\\
    (2): Так как
    \[Y\sim Pois\left(\sum\limits_{k=1}^{n}p_k\right)\]
    то по лемме 1 $P(Y\in B)=P(Y_1+\dots+Y_n\in B)$, где $Y_1,\dots,Y_n$ независимы и $Y_k \sim Pois(p_k)$\\
    (3): $X_1+\dots+X_n\neq Y_1+\dots+Y_n \subset \bigcup\limits_{k=1}^{n}\{X_k\neq Y_k\}$ это можно показать, используя тот факт, что $A\subset B \Leftrightarrow \overline{B}\subset \overline{A}$.\\
    (4): Суббаддитивность.\\ \\
    Введем $V_1,\dots,V_n$ независимые с $Y_1,\dots,Y_n$ такие, что $P(V_k=0)=(1-p_k)e^{p_k}$ и $P(V_k=1)=1-P(V_k=0)$, причем $(1-p_k)e^{p_k}\leq 1$, так как $e^{-p_k}\geq(1-p_k)$.
    Подберем $U_1,\dots,U_n$ такие, что 
    \[U_k=\begin{cases}
        1,\ \ p_k\\
        0,\ \ 1-p_k
    \end{cases}\]
    и $\{U_k=0\}=\{V_k=0,\ Y_k=0\}$,\ $\{U_k=1\}=\Omega\setminus \{U_k=0\}$.\\
    Отсюда
    \begin{multline*}
        P(U_k=0)=P(V_k=0, Y_k=0)=P(V_k=0)P(Y_k=0)=\\=(1-p_k)e^{p_k}\cdot \frac{\lambda^0 e^{-p_k}}{0!}=1-p_k
    \end{multline*}
    а следовательно $P(U_k=1)=1-(1-p_k)=p_k$, значит, случайная величина $X_k$ совпадает с $U_k$ и нам достаточно оценить $P(U_k\neq Y_k)$.
    \[P(U_k\neq Y_k)=P(U_k\neq Y_k,\ Y_k=0)+P(U_k\neq Y_k,\ Y_k=1)+P(U_k\neq Y_k,\ Y_k\geq 2)\]
    Разберем каждое слагаемое:
    \begin{enumerate}
        \item 
        \[P(U_k\neq Y_k,\ Y_k=0)=P(U_k=1,\ Y_k=0)\]
        \item Вспомним, что $\{U_k=0\}=\{V_k=0,\ Y_k=0\}$. Тогда
        \[P(U_k\neq Y_k,\ Y_k=1)=P(U_k=0,\ Y_k=1)=P(V_k=0,\ Y_k=0,\ Y_k=1)=0\]
        \item
        \[P(U_k\neq Y_k,\ Y_k\geq 2)=P(Y_k\geq 2)\]
    \end{enumerate}
    Итого:
    \[P(U_k\neq Y_k)=P(U_k=1,\ Y_k=0)+P(Y_k\geq 2)\]
    Снова анализируем слагаемые:
    \begin{enumerate}
        \item 
        \begin{multline*}
            P(U_k=1,\ Y_k=0)=P(Y_k=0)-P(U_k=0,\ Y_k=0)=\\
            =P(Y_k=0)-P(V_k=0,\ Y_k=0,\ Y_k=0)=\\
            =P(Y_k=0)-P(V_k=0,\ Y_k=0)=\\
            =e^{-p_k}-(1-p_k)e^{p_k}e^{-p_k}=p_k+e^{-p_k}-1
        \end{multline*}
        \item 
        \[P(Y_k\geq 2)=1-P(Y_k=0)-P(Y_k=1)=1-e^{-p_k}-p_k e^{-p_k}\]
    \end{enumerate}
    Получили:
    \begin{multline*}
        P(U_k\neq Y_k)=p_k+e^{-p_k}-1+1-e^{-p_k}-p_k e^{-p_k}=\\=p_k-p_ke^{-p_k}=p_k(1-e^{-p_k})\leq p_k^2
    \end{multline*}
    Таким образом:
    \[|P(S_n\in B)-P(Y\in B)|\leq \sum\limits_{k=1}^{n}P(U_k\neq Y_k)\leq \sum\limits_{k=1}^{n}p_k^2\]
\end{proof}
\noindent В доказательстве мы воспользовались теоремой
\begin{theorem} (Теорема Ломницкого-Улама)\\
    Пусть $(S_t,\mathcal{B}_t,Q_t)$ - семейство вероятностных пространств. Тогда на некотором вероятностном пространстве $(\Omega, \mathcal{F}, P)$ можно построить семейство независимых случайных элементов $X_t: \Omega\to S_t,\ X_t\in \mathcal{F}|\mathcal{B}_t$, причем $P_{X_t}=Q_t,\ t\in T$. Это означает, что всегда можно построить семейство независимых случайных элементов, имеющих заданное распределение.
\end{theorem}
\subsection{Расширенные случайные величины}
\begin{definition}
    Рассмотрим $\overline{\R}=\R\cup \{+\infty,-\infty\}$. Отображение $X: \Omega\to \overline{\R}$ назовем расширенной случайной величиной, если $X\in \mathcal{F}|\mathcal{B}(\overline{\R})$, где\\
    $\mathcal{B}(\overline{\R})=\{B,\ B\cup\{+\infty\},\ B\cup\{-\infty\},\ B\cup\{+\infty,\ -\infty\}: B\in \mathcal{B}(\R)\}$ 
\end{definition}
\begin{statement}
    $X$ - случайная величина (расширенная) $\Leftrightarrow \forall x\in \R:\\
    \{\omega: X(\omega)\leq x\}\in \mathcal{F}$
\end{statement}
\begin{theorem}
    Пусть $X_1, X_2, \dots $ - случайные величины (расширенные). Тогда справедливы следующие утверждения
    \begin{enumerate}
        \item $\sup\limits_n X_n,\ \inf\limits_n X_n$ - случайные величины (расширенные)
        \item $\lim\limits_{n\to\infty}\sup\limits_n X_n,\ \lim\limits_{n\to\infty}\inf\limits_n X_n$ - случайные величины (расширенные).
        \item Если существует предел $\lim\limits_{n\to\infty}X_n$, то он является случайной величиной (расширенной).
    \end{enumerate}
\end{theorem}
\begin{proof} Будем доказывать пользуясь утверждением
    \begin{enumerate}
        \item $\forall x\in \R$:
        \[\{\omega: \sup\limits_n X_n\leq x\}=\bigcap\limits_{n=1}^{\infty} \{\omega: X_n(\omega)\leq x\}\in \mathcal{F}\]
        \[\{\omega: \inf\limits_n X_n\leq x\}=\bigcup\limits_{n=1}^{\infty} \{\omega: X_n(\omega)\leq x\}\in \mathcal{F}\]
        \item Сведем к первому пункту
        \[\lim\limits_{n\to\infty}\sup\limits_n X_n(\omega)=\inf\limits_n \sup\limits_{k\leq n}X_k(\omega)\]
        \[\lim\limits_{n\to\infty}\inf\limits_n X_n(\omega)=\sup\limits_n \inf\limits_{k\leq n}X_k(\omega)\]
        \item Если существует предел, то он соппадает с верхним и нижним пределами, значит
        \[\lim\limits_{n\to\infty}X_n=\lim\limits_{n\to\infty}\sup\limits_n X_n\]
        а это, в свою очередь, является случайной величиной по пункту 2.
    \end{enumerate}
\end{proof}
\section{Лекция 6}
\subsection{Математическое ожидание}
\begin{definition}
    Пусть $(\Omega, \mathcal{F}, P)$ - вероятностное пространство, $X:\Omega \to \R,\\
    X\in \mathcal{F}|\mathcal{B}(\R)$. Математическим ожиданием случайной величины $X$ назовем интеграл Лебега от случайной величины по вероятностной мере
    \[EX=\int\limits_{\Omega}X\ d(P)\]
\end{definition}
\noindent Таким образом, для определения понятия математического ожидания случайной величины, необходимо ввести понятие интеграла Лебега от случайной величины по вероятностной мере.
\subsection{Построение интеграла Лебега}
Построение интеграла Лебега происходит в три этапа:
\begin{enumerate}
    \item Для простых случайных величин.
    \item Для неотрицательных случайных величин.
    \item Для произвольных случайных величин. 
\end{enumerate}
\subsubsection{Первый этап}
\begin{definition}
    Случайная величина $X$ называется простой, если 
    \[X(\omega)=\sum\limits_{k=1}^{n}a_k I_{A_k}\]
    где $A_1, \dots, A_n\in \mathcal{F}$ образуют разбиение $\Omega$.
\end{definition}
\begin{definition}
    Если $X$ - простая случайная величина, то 
    \[EX=\int\limits_{\Omega}X\ dP=\sum\limits_{k=1}^{n}a_k P(A_k)=\sum\limits_{k=1}^{n}a_k P(X=a_k)\]
\end{definition}
\begin{statement}
    Приведенное выше определение корректно.
\end{statement}
\begin{proof}
    Пусть $B_1,\dots,B_m$ - другое разбиение $\Omega$ и 
    \[X=\sum\limits_{j=1}^{m}b_j I_{B_j}\]
    необходимо показать, что
    \[\sum\limits_{k=1}^{n}a_k P(A_k)=\sum\limits_{j=1}^{m}b_j P(B_j)\]
    Рассмотрим $C_{kj}=A_k\cap B_j$ - новое разбиение $\Omega$. Тогда, по формуле полной вероятности:
    \begin{multline*}
        \sum\limits_{k=1}^{n}a_k P(A_k)=\sum\limits_{k=1}^{n} a_k \sum\limits_{j=1}^{m}P(A_k\cap B_j)=\sum\limits_{k=1}^{n}\sum\limits_{j=1}^{m}a_k P(c_{kj})=\\
        =\sum\limits_{(k,j)\in J} a_k P(C_{kj})=\sum\limits_{(k,j)\in J} b_j P(C_{kj})=\sum\limits_{j=1}^{m} b_j P(B_j)
    \end{multline*}
    где $J=\{(k,j): C_{kj}\neq \emptyset\}$. Если $C_{kj}\neq \emptyset$, то $X(\omega)=a_k=b_j,\ \forall \omega\in C_{kj}$
\end{proof}
\begin{theorem} Для простых случайных величин $X$ и $Y$ справедливы следующие утверждения:
    \begin{enumerate}
        \item $E(X+Y)=EX+EY$.
        \item $\forall c\in \R: E(cX)=c\cdot EX$.
        \item Если $X\geq 0$, то $EX\geq 0$.
        \item Если $X\leq Y$, то $EX\leq EY$.
    \end{enumerate}
\end{theorem}
\begin{proof}\tab
    \begin{enumerate}
        \item Рассмотрим два случая
        \begin{enumerate}
            \item Для $X$ и $Y$ одно и то же разбиение $A_1, \dots, A_n$ на $\Omega$. В этом случае, $\forall \omega \in A_k: X+Y(\omega)=X(\omega)+Y(\omega)=a_k+b_k$. Отсюда
            \[E(X+Y)=\sum\limits_{k=1}^{n}(a_k+b_k)P(A_k)=\sum\limits_{k=1}^{n}a_k P(A_k)+\sum\limits_{k=1}^{n}b_kP(A_k)=EX+EY\]
            \item Если разбиения $A_1,\dots, A_n$ для $X$ и $B_1,\dots,B_m$ для $Y$ оказались разными, то рассмотрим новое разбиение $C_{kj}=A_k\cap B_j$. Таким образом, свели к первому случаю.
        \end{enumerate}
        \item $\forall c\in \R$:
        \[E(cX)=\sum\limits_{k=1}^{n}c\cdot a_k P(A_k)=c\cdot \sum\limits_{k=1}^{n}a_k P(A_k)=c\cdot EX\]
        \item Если $X\geq 0$, то $a_k\geq 0$. Значит
        \[EX=\sum\limits_{k=1}^{n}a_k P(A_k)\geq 0\]
        \item Пусть $X\geq Y \Rightarrow X-Y\geq 0 \Rightarrow E(X-Y)\geq 0$. Тогда из доказанных свойств:
        \[E(X-Y)=E(X+(-1)\cdot Y)=EX+E((-1)\cdot Y)=EX-EY\geq 0\]
    \end{enumerate}
\end{proof}
\subsubsection{Второй этап}
\begin{definition}
    Пусть $X\geq 0$ случайная величина. Тогда
    \[EX=\sup\{EY: 0\leq Y\leq X,\ Y - \text{простая}\}\]
\end{definition}
\begin{lemma}
    Пусть $X\geq 0$ случайная величина. Тогда существует последовательность простых функций $X_n\geq 0$ таких, что $X_n\to X$ и $X_{n}(\omega)\leq X_{n+1}(\omega),\ \forall \omega\in \Omega$
\end{lemma}
\begin{proof}
    Возьмем последовательность
    \[X_n=\min\{(2^{-n}\ [2^n X]\ ),\ n\}\]
    Заметим, что
    \[X_n(\omega)=\begin{cases}
        k2^{-n},\ \ k2^{-n}\leq X(\omega)<(k+1)2^{-n},\ k=0, 1, \dots, n2^n-1,\\
        n\ \ \ \ \ , \ \ X(\omega)\geq n.
    \end{cases}\]
    \[|X_n(\omega)-X(\omega)|\leq 2^{-n}\to 0\]
    Тогда $X_n\to X$.
\end{proof}
\begin{lemma}
    Пусть $X\geq 0$ случайная величина. Тогда для любой последовательности простых функций $0\leq X_n\leq X,\ X_n\to X$ выполнено, что $EX_n\to EX$.
\end{lemma}
\begin{proof}
    $X_n$ - простые и $X_{n}\leq X_{n+1} \Rightarrow EX_n \leq EX_{n+1}$. При этом
    \[EX=\sup\{EY: 0\leq Y\leq X,\ Y - \text{простая}\}\]
    значит существует предел 
    \[\lim\limits_{n\to\infty}EX_n=a\leq EX\]
    Покажем, что выполнено и обратное неравенство. Для этого докажем, что для любой простой фунции $0 \leq Y\leq X$ выполнено, что $EY\leq a$. Если $Y\equiv 0$, то утверждение верно. Пусть
    \[Y=\begin{cases}
        0=b_0< b_1 < \dots < b_k\\
        \ \ \ \ \ \ p_0,\ \ p_1\ \ ,\  \dots\ ,\ p_k
    \end{cases}\]
    Тогда
    \[EY=\sum\limits_{j=1}^{k}b_j p_j\]
    Введем $Y_n=(1-\epsilon)Y \cdot I\{(1-\epsilon)Y\leq X_n\},\ n\in \N,\ \epsilon\in (0,1)$. Из определения
    $Y_n\leq X_n \Rightarrow EY_n\leq EX_n\leq a$. Пусть 
    \[B_j=\{\omega: Y(\omega)=b_j\},\ C_{jn}=\{(1-\epsilon)Y\leq X_n\}\]
    Тогда $Y_n(\omega)=(1-\epsilon)b_j$, если $\omega\in B_j\cap C_{jn}$. Получаем, что
    \[EY_n=\sum\limits_{j}(1-\epsilon)b_j P(B_j\cap C_{jn})\]\
    При этом, по свойству непрерывности вероятностной меры
    \[P(B_j\cap C_{jn})\to P(B_j)\]
    следовательно
    \[EY_n=\sum\limits_{j}(1-\epsilon)b_j P(B_j\cap C_{jn})\to (1-\epsilon)\sum\limits_{j}b_j P(B_{j})=(1-\epsilon)EY\]
    Получили, что $\forall \epsilon\in (0,1):$
    \[(1-\epsilon)EY\leq a\]
    тогда, устремив $\epsilon\to 0$, получим для любой $Y: EY\leq a \Rightarrow EX\leq a$. Из полученных неравентв, следует, что
    \[\lim\limits_{n\to\infty}EX_n=EX\]
\end{proof}
\begin{lemma}
    Пусть $X, Y\geq 0$ случайные величины. Тогда
    \begin{enumerate}
        \item $E(X+Y)=EX+EY$.
        \item $\forall c\geq 0: E(cX)=c\cdot EX$
    \end{enumerate}
\end{lemma}
\begin{proof}\tab
    \begin{enumerate}
        \item Возьмем неубывающие последовательности простых функций $X_n\to X,\\
        Y_n\to Y$. Тогда $X_n+Y_n\to X+Y$ и по лемме 2: 
        \[E(X_n+Y_n)=EX_n+EY_n\to E(X+Y)\]
        \item Возьмем неубывающую последовательность простых функций $X_n\to X$. Тогда $cX_n\to cX$ и $E(cX_n)\to E(cX)$ и по лемме 2:
        \[E(cX_n)=c\cdot E(X_n)\to c\cdot E(X)\]
    \end{enumerate}
\end{proof}
\subsubsection{Третий этап}
\begin{comm}
    Заметим, что любую функцию $X:\Omega\to \R$ можно представить в виде $X=X^+-X^-$, где 
    \[X^+=\max\{X,\ 0\}=X\cdot I\{X\geq 0\},\ \ X^-=-\min\{X, 0\}=-X\cdot I\{X\leq 0\}\]
\end{comm}
\begin{definition} Пусть $X$ - произвольная случайная величина. Тогда
    \[EX=EX^+-EX^-\]
    по определению положим, что $EX$ не существует, если $EX^+=+\infty$ и $EX^-=+\infty$ одновременно. Также по определению для любой константы $+\infty - c=+\infty$ и $c - \infty = -\infty$
\end{definition}
\begin{definition}
    Если $EX\in \R$, то случайная величина $X$ называется интегрируемой по Лебегу и обозначается $X\in \mathcal{L}^1$
\end{definition}
\begin{theorem}
    Для произвольной случайной величины справедливы следующие утверждения:
    \begin{enumerate}
        \item Если $Y\leq X$ и $X\in \mathcal{L}^1$, то $Y\in \mathcal{L}^1$.
        \item Если $X,Y\in \mathcal{L}^1$ и $Y\leq X$, то $EY\leq EX$.
        \item Если $X\in \mathcal{L}^1$, то $|EX|\leq E|X|$.\
        \item $\mathcal{L}^1$ - линейное пространство.
        \item $E$ - линейный функционал.
    \end{enumerate}
\end{theorem}
\subsection{Дополнение (материалы с семинара)}
\begin{statement}
    Если $X$ - Бернуллиевская случайная величина, то $EX=p$.
\end{statement}
\begin{statement}
    Если $X\sim B(n,p)$, то $EX=np$.
\end{statement}
\begin{statement}
    Если $X\sim Pois(\lambda)$, то $EX=\lambda$
\end{statement}
\begin{statement}
    Если $X$ и $Y$ независимые случайные величины, то $E(XY)=EX\cdot EY$
\end{statement}
\section{Лекция 7}
\subsection{Теорема о монотонной сходимости}
\begin{theorem} (Теорема о монотонной сходимости)\\
    Пусть $X_n\geq 0$ случайные величины и $X_n\nearrow X$. Тогда $EX_n\to EX$.
\end{theorem}
\begin{proof}
    Пусть
    \[\begin{matrix}
        0 \leq Y_{n,1}\nearrow  X_1\\
        0 \leq Y_{n,2}\nearrow  X_2\\
        \vdots\\
        0 \leq Y_{n,k}\nearrow  X_k
    \end{matrix}\]
    где $X_1\leq X_2\leq \dots \leq X_k \to X,\ Y_{n,i}$ - простые. Рассмотрим  
    \[\begin{matrix}
        Y_{1,1}\ \leq Y_{2,1}\leq \dots \leq Y_{k,1} \leq \dots \leq Y_{n,1} \nearrow X_1\\
        \vdots\\
        Y_{1,k}\ \leq Y_{2,k}\leq \dots \leq Y_{k,k} \leq \dots \leq Y_{n,k} \nearrow X_k
    \end{matrix}\]
    и определим 
    \[0\leq Z_k := \max\limits_{1\leq i,j\leq k}Y_{i,j}\nearrow Z\]
    Таким образом
    \[0\leq Y_{n,k}\leq Z_k\leq X_k\leq X \eqno{(1)}\]
    После предельного перехода при $k\to \infty$, получим
    \[0\leq X_n\leq Z\leq X\]
    После предельного перехода при $n\to \infty$, получим
    \[0\leq Z_k \nearrow X \eqno{(2)}\]
    Так как $X_n\leq X$, то $EX_n\leq EX$, а значит
    \[\lim\limits_{n\to\infty} EX_n\leq EX\]
    Также из $(1)$ и $(2)$ имеем:
    \[EZ_n\leq EX_n\]
    и как следствие 
    \[EX\leq \lim\limits_{n\to\infty} EX_n\]
\end{proof}
\begin{statement}
    Рассмотрим вероятностные пространства $(\Omega, \mathcal{F}, P),\ (S, \mathcal{B}, P_X),\\
    X\in \mathcal{F}|\mathcal{B}$, где $\forall B\in \mathcal{B}: P_X(B)=P(X^{-1}(B))$, т.е $P_X$ - мера на $(S,\mathcal{B})$, индуцированная $X$. Также рассмотрим вероятностное пространство $(\R,\ \mathcal{B}(\R))$ и $h\in \mathcal{\mathcal{B}}|\mathcal{B}(\R)$. Теперь рассмотрим композицию отображений $h(X(\omega))\in \mathcal{F}|\mathcal{B}(\R)$. Тогда оба интеграла существуют или не существуют одновременно, и если существуют, то равны:
    \[Eh(X)=\int\limits_{\Omega}h(X(\omega))P(d\omega)=\int\limits_{S}h(x)P_X(dx)\]
\end{statement}
\begin{proof}
    Сначала пусть $h$ - индикатор:
    \[h(x)=I_B(x)=\begin{cases}
        1,\ x\in B,\\
        0,\ x\not\in B
    \end{cases}\]
    \[\int\limits_{S}h(x)P_X(dx)=1\cdot P_X(B)=P(X^{-1}(B))\]
    \[\int\limits_{\Omega}h(X(\omega))P(d\omega)=1\cdot P(X^{-1}(B))\]
    Тогда формула будет верна для линейной комбинации индикаторов, а значит для простых $h\geq 0$. По теореме о монотонной сходимости, формула будет верна для произвольной
    \[h=h^+-h^-\]
\end{proof}
\begin{comm}
    Пусть дискретная случайная величина
    \[X=\begin{cases}
        x_1,\ x_2, \dots\\
        p_1,\ p_2, \dots
    \end{cases}\]
    \[Eh(X)=\sum\limits_{h(x_n)\geq 0}h(x_n)P(X=x_n)+\sum\limits_{h(x_n)< 0}h(x_n)P(X=x_n)\]
    То есть конечное $Eh(X)$ существует, если 
    \[\sum\limits_{n} |h(x_n)|\cdot P(X=x_n)<\infty\]
\end{comm}
\subsection{Дисперсия случайной величины}
\begin{definition}
    Рассмотрим случайную величину $X$. Пусть $X\in \mathcal{L}^1,\\
    (X-EX)^2\in \mathcal{L}^1$. Тогда дисперсией случайной величины $X$ называется выражение
    \[\var{X}=E(X-EX)^2\]
\end{definition}
\begin{comm}
    $(X-EX)^2=X^2-2XEX+(EX)^2\in \mathcal{L}^1 \Rightarrow X\in \mathcal{L}^2$
\end{comm}
\begin{comm}
    Если $X$ - дискретная случайная величина, то
    \[\var{X}=\sum\limits_{n}(X_n-EX)^2 P(X=x_n)\]
\end{comm}
\begin{definition}
    Рассмотрим случайные величины $X$ и $Y$. Пусть $X,Y\in \mathcal{L}^1,\\
    (X-EX)\in \mathcal{L}^1$. Тогда ковариацией случайных величин $X$ и $Y$ называется выражение
    \[\cov{(X,Y)}=E((X-EX)(Y-EY))\]
\end{definition}
\begin{comm}
    \[\cov{(X,X)}=\var{X}\]
\end{comm}
\begin{theorem}
    Пусть $X_1, X_2, \dots\in \mathcal{L}^2$ - случайные величины. Тогда 
    \[\var\left(\sum\limits_{k=1}^{n} X_k\right)=\sum\limits_{k=1}^{n}\var{X_k}+2 \sum\limits_{1\leq i<j\leq n} \cov{(X_i,X_j)}\]
\end{theorem}
\begin{proof}
    \begin{multline*}
        \var{\left(\sum\limits_{k=1}^{n}X_k\right)}=E\left(\sum\limits_{k=1}^{n}X_k-E\left(\sum\limits_{k=1}^{n}X_k\right)\right)^2\overset{(1)}{=}\\
        \overset{(1)}{=}E\left(\sum\limits_{k=1}^{n}\left(X_k-EX_K\right)\right)^2\overset{(2)}{=}E\left(\sum\limits_{i,j=1}^{n}(X_i-EX_i)(X_j-EX_j)\right)\overset{(1)}{=}\\
        \overset{(1)}{=}\sum\limits_{i,j=1}^{n}E((X_i-EX_i)(X_j-EX_j))=\sum\limits_{i,j=1}^{n}\cov{(X_i,X_j)}
    \end{multline*}
    (1): По линейности математического ожидания:
    \[E\left(\sum\limits_{k=1}^{n}X_k\right)=\sum\limits_{k=1}^{n}EX_k\]
    (2): Поскольку 
    \[\left(\sum\limits_{k=1}^{n}a_k\right)^2=(a_1+\dots+a_n)(a_1+\dots+a_n)\]
    Итак, поскольку $\cov{(X,X)}=\var{X}$, то 
    \[\var\left(\sum\limits_{k=1}^{n} X_k\right)=\sum\limits_{k=1}^{n}\var{X_k}+2 \sum\limits_{1\leq i<j\leq n} \cov{(X_i,X_j)}\]
\end{proof}
\begin{consequense}
    Пусть $X_1, X_2, \dots\in \mathcal{L}^2$ - независимые случайные величины. Тогда
    \[\var\left(\sum\limits_{k=1}^{n}X_k\right)=\sum\limits_{k=1}^{n}\var{X_k}\]
\end{consequense}
\begin{proof}
    Если $X_1,\dots,X_n$ - независимы в совокупности, то они попарно независимы, тогда независимы величины $X_i-EX_i$ и $X_j-EX_j$. Тогда
    \[E((X_i-EX_i)(X_j-EX_j))=E(X_i-EX_i)\cdot E(X_j-EX_j)=0\]
    так как
    \[E(X_i-EX_i)=EX_i-EX_i=0\]
\end{proof}
\subsection{Неравенство Маркова}
\begin{theorem} (Неравенство Маркова)\\
    Пусть $f:R_+\to R_+,\ f$ - не убывает. Тогда для любой случайной величины $X$ и $\forall t\geq 0$:
    \[Ef(|X|)\geq f(t)\cdot P(|X|\geq t)\]
\end{theorem}
\begin{proof}
    \[f(|X|)\geq f(|X|)\cdot I\{|X|\geq t\}\geq f(t)\cdot I\{|X|\geq t\}\]
    Значит
    \[Ef(|X|)\geq E(f(t)\cdot I\{|X|\geq t\})=f(t)\cdot E(I\{|X|\geq t\})=f(t)\cdot P(|X|\geq t)\]
\end{proof}
\begin{consequense} (Неравенство Бьенеме-Чебышёва)\\
    \[P(|X-EX|\geq \epsilon)\leq \frac{\var{X}}{\epsilon^2}\]
\end{consequense}
\begin{proof}
    Возьмем $f(t)=t^2$. По неравенству Маркова:
    \[P(|X-EX|\geq \epsilon)\leq \frac{Ef(|X-EX|)}{f(\epsilon)}=\frac{E(X-EX)^2}{\epsilon^2}=\frac{\var{X}}{\epsilon^2}\]
\end{proof}
\subsection{Бернуллиевские случайные величины}
\begin{definition}
    Случайная величина $X$ называется бернуллиевской, если она принимает всего два значения $0$ и $1$ с вероятностями
    \[P(X=1)=p,\ \ P(X=0)=1-p\]
\end{definition}
\begin{theorem} (Теорема Бернулли)\\
    Пусть $X_1,X_2,\dots$ независимые случайные Бернуллиевские случайные величины, $S_n=X_1+\dots+X_n$ и $\var{X_k}\leq C$. Тогда $\forall \epsilon>0$
    \[P\left(\ \left|\frac{S_n}{n}-p\right|\geq \epsilon\right)\to 0,\ n\to \infty\]
    Это означает, что $\frac{S_n}{n}$ при больших $n$ имеют как-бы неслучайный порядок поведения.
\end{theorem}
\begin{proof}
    \begin{multline*}
        p\left(\ \left|\frac{S_n}{n}-\frac{1}{n}\cdot \sum\limits_{k=1}^{n}EX_k\right|\geq \epsilon\right)=P(|S_n-ES_n|\geq n\epsilon)\overset{(1)}{\leq}\frac{\var{S_n}}{(n\epsilon)^2}=\\
        =\frac{1}{n^2\epsilon^2}\cdot \sum\limits_{k=1}^{n}\var{X_k}\leq \frac{C\cdot n}{n^2\epsilon^2}=\frac{C}{n\epsilon^2}\to 0,\ n\to \infty
    \end{multline*}
    (1): По неравенству Бьенеме-Чебышёва.
\end{proof}
\begin{definition}
    Случайные величины $Z_n$ сходятся по вероятности в $Z$, если $\forall \epsilon>0:$
    \[P(|Z_n-Z|\geq \epsilon)\to 0\]
    обозначают
    \[Z_n\overset{P}{\to}Z\]
\end{definition}
\noindent Таким образом, теорема Бернулли показывает, что 
\[\frac{S_n}{n}\overset{P}{\to}p,\ n\to \infty\]
Это простейшая (слабая) форма закона больших чисел.
\subsection{Теорема Вейерштрасса об аппроксимации}
\begin{theorem} (Теорема Вейерштрасса об аппроксимации)\\
    Пусть $f(x)$ непрерывна на $[a,b]$. Тогда $\forall \epsilon>0$ существует многочлен $P_n(x)$ такой, что
    \[\sup\limits_{x\in [a,b]}|f(x)-P_n(x)|<\epsilon\]
\end{theorem}
\begin{proof}
    Временно пропущено
\end{proof}
\section{Лекция 8}
\subsection{Стабильность случайных величин}
\begin{lemma}
    $E|X|=0 \Leftrightarrow X=0$ почти наверное, то есть $\forall \omega\not\in A,\\ P(A)=0: X(\omega)=0$
\end{lemma}
\begin{proof}
    Достаточно доказать для неотрицательных случаных величин, поскольку $X=X^+-X^-$ и
        \[X=0 \Leftrightarrow \begin{cases}
            X^+=0\\
            X^-=0
        \end{cases}\]
        Далее $X\geq 0$.
    \begin{itemize}
        \item[($\Rightarrow$):] Пусть $E|X|=0$.
        По неравенству Маркова $\forall n\in \N$:
        \[P\left(|X|\geq \frac{1}{n}\right)\leq \frac{E|X|}{\frac{1}{n}}=0\]
        \[\{|X|>0\}=\bigcup\limits_{n=1}^{\infty}\{|X|\geq \frac{1}{n}\}\]
        \[P(|X|>0)\leq \sum\limits_{n=1}^{\infty}P(|X|\geq \frac{1}{n})=0\]
        \item[$(\Leftarrow)$:] Пусть $X=0$ почти наверное,\ $X\geq 0 \Rightarrow EX\geq 0$. Рассмотрим 
        \[EX_n\to EX,\ 0\leq X_n\nearrow X,\ X_n=2^{-n}[2^nX]\wedge n\]
        Заметим, что $\{X_n\in [0,2^{-n})\}\subset \{X_n=0\}$
        \[EX_n=\sum\limits_{k=0}^{n2^n}k2^{-n}P(k2^{-n}\leq X\leq (k+1)2^{-n})=0\]
        Значит $\forall n\in \N: EX_n=0 \Rightarrow EX=0$.
    \end{itemize}
\end{proof}
\begin{consequense}
    Если $X=Y$ почти наверное и $X\in \mathcal{L}^1$, то $Y\in \mathcal{L}^1$ и $EX=EY$.
\end{consequense}
\begin{proof}
    $Y=X+Y-X,\ X=Y$ почти наверное $\Rightarrow Y-X=0$ почти наверное. Отсюда существует
    \[EY=EX+E(Y-X)=EX\]
\end{proof}
\begin{statement}
    Отношение $X\sim Y \Leftrightarrow X=Y$ почти наверное - отношение эквивалентности.
\end{statement}
\begin{proof}\tab
    \begin{enumerate}
        \item $P(X=X)=1 \Rightarrow X\sim X$.
        \item $X\sim Y \Rightarrow P(X\neq Y)=0$ и так как $\{X\neq Y\}=\{Y\neq X\}$, то $P(Y\neq X)=0\\
        \Rightarrow Y\sim X$.
        \item $X\sim Y$ и $Y\sim Z \Rightarrow P(X\neq Y)=0$ и $P(Y\neq Z)=0$. Заметим, что если $X\neq Z$, то либо $X\neq Y$, либо $Y\neq Z$, то есть 
        \[\{X\neq Z\}\subset \{X\neq Y\}\cup \{Y\neq Z\}\]
        Отсюда
        \[P(X\neq Z)\leq P(X\neq Y)+P(Y\neq Z)=0+0=0\]
        значит $X\sim Z$.
    \end{enumerate}
\end{proof}
\begin{definition}
    Определим пространство $L^p$ как совокупность классов эквивалентности величин из $\mathcal{L}^p$.
\end{definition}
\begin{statement}
    Если $p\geq 1$, то $L^p$ - нормированное пространство, причем\\
    $\forall X\in L^p:$
    \[\|X\|=(E|X|^p)^{\frac{1}{p}}\]
\end{statement}
\begin{statement}
    $L^2$ является гильбертовым пространством, причем
    \[(X,Y)=E(XY),\ \ \|X\|_2=(EX^2)^{\frac{1}{2}}\]
    то есть 
    \[\rho(X,Y)=\|X-Y\|_2\]
    по этой норме $L_2$ - полно.
\end{statement}
\begin{lemma} (Неравенство Коши-Буняковского-Шварца)\\
    Пусть $H$ - гильбертово пространство. Тогда $\forall X,Y\in H:$
    \[|(X,Y)|\leq \|X\|\cdot \|Y\|\]
\end{lemma}
\begin{proof}
    Для $t\in \R$ рассмотрим 
    \[(tX+Y, tX+Y)=t^2(X,X)+2(X,Y)t+(Y,Y)\geq 0\]
    отсюда
    \[D=(X,Y)^2-(X,X)(Y,Y)\leq 0\]
\end{proof}
\begin{definition}
    Пусть $X,Y\in L^2,\ \var{X}\neq 0,\ \var{Y}\neq 0$. Коэффициентом корреляции Пирсона называется
    \[\rho(X,Y)=\frac{\cov{(X,Y)}}{\sqrt{\var{X}\cdot \var{Y}}}\]
    \[\cov{(X,Y)}=E((E-EX)(Y-EY))\]
    отсюда, по неравенству КБШ: $\rho(X,Y)\leq 1$
\end{definition}
\begin{exercise}
    $|\rho(X,Y)|=1 \Leftrightarrow X$ и $Y$ - линено зависимы.
\end{exercise}
\begin{comm}
    Далее равенство случайных величин всегда подразумеваем как равенство почти наверное.
\end{comm}
\subsection{Разные виды сходимостей}
\begin{definition} (Сходимость почти наверное)\\
    $X_n\to X$ почти наверное, если 
    \[P(\{\omega: X_n(\omega)\not\to X(\omega)\})=0\]
\end{definition}
\begin{definition} (Сходимость по вероятности)\\
    \[X_n\overset{P}{\to} X\ \Leftrightarrow\ \forall \epsilon>0:\ P(\{\omega: |X_n(\omega)-X(\omega)|\geq \epsilon\})\to 0\]
\end{definition}
\begin{definition} (Сходимость в $L^p$)\\
    \[X_n\overset{L^p}{\to} X\ \Leftrightarrow\ E|X_n-X|^p\to 0\]
\end{definition}
\begin{definition} (Сходимость по распределению)\\
    \[X_n\overset{D}{\to} X\ \Leftrightarrow\ \forall f\in \mathcal{C}_b(\R,\R):\ Ef(X_n)\to Ef(X)\]
\end{definition}
\begin{theorem}
    Справедливы следующие соотношения
    \begin{enumerate}
        \item Сходимость почти наверное $\Rightarrow$ cходимость по вероятности.
        \item Сходимость по вероятности $\Rightarrow$ cходимость по распределению.
        \item Сходимость в $L^p$ $\Rightarrow$ сходимость по вероятности.
    \end{enumerate}
\end{theorem}
\begin{proof}
    \begin{enumerate}
        \item 
    \end{enumerate}
\end{proof}
\begin{lemma} (Лемма Слуцкого)\\
    Пусть
    \[X_n\overset{D}{\to}X,\ \ Y_n\overset{P}{\to}c\]
    Тогда
    \begin{enumerate}
        \item \[X_n+Y_n\overset{D}{\to}X+c\]
        \item \[X_n\cdot Y_n\overset{D}{\to} cX\]
    \end{enumerate}
\end{lemma}
\section{Лекция 9}
\subsection{Теорема Райхмана}
\begin{theorem} (Теорема Райхмана)\\
    Пусть $X_1,X_2\dots$ случайные величины такие, что при $i\neq j$:
    $\cov{(X_i,X_j)}=0$ и $\forall i: \var{X_i}\leq C$ и $S_n=X_1+\dots+X_n$. Тогда
    \[\frac{S_n-ES_n}{n}\to 0\ \ \ \text{почти наверное}\]
\end{theorem}
\begin{proof}
    будет
\end{proof}
\subsection{Теорема Колмогорова}
\begin{lemma}
    Для любой случайной величины $X$ справедливо соотношение
    \[\sum\limits_{n=1}^{\infty}P(|X|\geq n)\leq E|X|\leq \sum\limits_{n=1}^{\infty}P(|X|\geq n)+1\]
\end{lemma}
\begin{proof}
    тут норм
\end{proof}
\begin{theorem} (Теорема Колмогорова)\\
    Пусть $X_1,X_2$ независимые, одинаково распределенные случайные величины. Тогда
    \[\frac{S_n}{n}\to c\in \R\ \ \text{почти наверное}\ \Leftrightarrow\ \exists\ EX_1=c\]
\end{theorem}
\begin{proof}
    ну это жестко
\end{proof}
\section{Лекция 10}
Большая часть лекции была потрачена на завершение доказательства теоремы Колмогорова.
\subsection{Равномерная интегрируемость}
\begin{definition}
    Семейство $\{X_t,\ t\in T\}$ действительных случайных величин называется равномерно интегрируемым, если 
    \[\lim\limits_{c\to\infty}\sup\limits_{t\in T}E(|X_t|\cdot I\{|X_t\geq c|\})=0\]
\end{definition}
\begin{statement}
    Пусть $\forall t\in T: |X_t|\leq Y,\ EY<\infty$. Тогда $\{X_t,\ t\in T\}$ равномерно интегрируемо.
\end{statement}
\begin{theorem}
    Семейство $\{X_t, t\in T\}$ равномерно интегрируемо тогда и только тогда, когда
    \begin{enumerate}
        \item $\sup\limits_{t\in T}E|X_t|<\infty$.
        \item $\forall \epsilon>0\ \exists\ \delta>0: P(A)\leq \delta \Rightarrow E(|X|\cdot I_A)<\epsilon$
    \end{enumerate}
\end{theorem}
\begin{proof}
    будет.
\end{proof}
\begin{theorem} (Теорема Де ла Валле-Пуссена)\\
    Семейство $\{X_t, t\in T\}$ равномерно интегрируемо $\Leftrightarrow$ существует выпуклая функция $G: R_+\to \R_+$ такая, что
    \begin{enumerate}
        \item \[\frac{G(x)}{x}\to \infty,\ x\to \infty\]
        \item \[\sup\limits_{t\in T}EG(|X_t|)<\infty\]
    \end{enumerate}
\end{theorem}
\section{Лекция 11}
\subsection{Разное}
\begin{theorem}
    Пусть $X_n, X\in L^p$ для некорого $p\geq 1$ и $X_n\to X,\ n\to \infty$. Тогда следующие утверждения эквивалентны:
    \begin{enumerate}
        \item $\{X_t, t\in T\}$ равномерно интегрируемо.
        \item $X_n\overset{L^p}{\to}X,\ n\to \infty$.
        \item $\|X_n\|_p\to \|X\|,\ n\to \infty$.
    \end{enumerate}
\end{theorem}
\begin{lemma} (Лемма Фату)\\
    Пусть $X_n\geq Y,\ EY>-\infty$. Тогда
    \[E(\lim\limits_{k}\inf|X_k|^p) \leq \lim\limits_{k}\inf E(|X_k|^p)\]
\end{lemma}
\begin{theorem} (Теорема Хартмана-Винтера, Закон повторного логарифма)\\
    Пусть $X_1, X_2$ независимые одинаково распределенные случайные величины, $EX_1=0,\ EX_1^2=1$. Тогда с вероятностью 1 произойдут события:
    \begin{enumerate}
        \item \[\lim\limits_{n\to\infty}\sup \frac{S_n}{\sqrt{2n\ln\ln(n)}}=1\]
        \item \[\lim\limits_{n\to\infty}\inf \frac{S_n}{\sqrt{2n\ln\ln(n)}}=-1\]
    \end{enumerate}
\end{theorem}
\begin{theorem} (Теорема Леви, Центральная предельная теорема)\\
    Пусть $X_1, X_2$ независимые одинаково распределенные случайные величины, $EX_1=a,\ \var{X_1}=\sigma^2>0$. Тогда
    \[\frac{S_n-na}{\sigma\sqrt{n}}\overset{D}{\to}Z\sim N(0,1)\]
\end{theorem}
\begin{theorem} (Теорема Радона-Никодима)\\
    Пусть $Q$ и $P$ --- $\sigma$-конечные меры на $(S,\mathcal{B})$. Тогда
    \[Q<<P \Leftrightarrow Q(B)=\int\limits_{S}f(x)P(dx)\]
    где $f$ - интегрируема по мере $P$.
\end{theorem}
\end{document}